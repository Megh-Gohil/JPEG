{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(image_path):\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # result_array = image_path - 128\n",
    "    result_array = image_array - 128\n",
    "    print(result_array)\n",
    "    pad_height = (8 - (result_array.shape[0] % 8)) % 8\n",
    "    pad_width = (8 - (result_array.shape[1] % 8)) % 8\n",
    "\n",
    "\n",
    "    padded_image = np.pad(result_array, ((0, pad_height), (0, pad_width)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DCT computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DCT(image, qmat):\n",
    "    dct_coeff_quant = np.zeros((8, image.shape[1]*image.shape[0]//8))\n",
    "    for i in range(image.shape[0]//8):\n",
    "        for j in range(image.shape[1]//8):\n",
    "            block = image[8*i:8*i+8, 8*j: 8*j+8]\n",
    "            dct_coeff_quant[:, image.shape[1]*i + 8*j : image.shape[1]*i + 8*(j+1)] = np.round(dct(dct(block.T, norm=\"ortho\").T, norm=\"ortho\") / qmat).astype(int)\n",
    "    print(np.max(dct_coeff_quant))\n",
    "\n",
    "    return dct_coeff_quant.astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Huffman encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode:\n",
    "    def __init__(self, symbol, freq):\n",
    "        self.symbol = symbol\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def build_huffman_tree(freq_table):\n",
    "    heap = [HuffmanNode(sym, freq) for sym, freq in freq_table.items()]\n",
    "    heapq.heapify(heap)\n",
    "\n",
    "    while len(heap) > 1:\n",
    "        left = heapq.heappop(heap)\n",
    "        right = heapq.heappop(heap)\n",
    "        merged = HuffmanNode(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(heap, merged)\n",
    "    return heap[0]\n",
    "\n",
    "def generate_huffman_codes(freq_table):\n",
    "    codes = {}\n",
    "    tree = build_huffman_tree(freq_table)\n",
    "    def generate_codes_helper(node, current_code):\n",
    "        if node.symbol is not None:\n",
    "            codes[node.symbol] = current_code\n",
    "            return\n",
    "        generate_codes_helper(node.left, current_code + \"0\")\n",
    "        generate_codes_helper(node.right, current_code + \"1\")\n",
    "\n",
    "    generate_codes_helper(tree, \"\")\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_order(n):\n",
    "    indices = [(x, y) for x in range(n) for y in range(n)]\n",
    "    zigzag_indices = sorted(indices, key=lambda x: (x[0] + x[1], -x[0] if (x[0] + x[1]) % 2 == 0 else x[0]))\n",
    "    # return [block[x, y] for x, y in zigzag_indices]\n",
    "    return zigzag_indices\n",
    "\n",
    "def run_length_encode(zigzag_block, huffman_codes):\n",
    "    encoded = []\n",
    "    run_length = 0\n",
    "\n",
    "    for coefficient in zigzag_block:\n",
    "        if coefficient == 0:\n",
    "            run_length += 1\n",
    "        else:\n",
    "            size = len(huffman_codes[coefficient])  # Number of bits in Huffman code\n",
    "            while run_length > 15:  # Handle long runs of zeros\n",
    "                encoded.append((15, 0, None))  # Special code for run of 16 zeros\n",
    "                run_length -= 15\n",
    "            encoded.append((run_length, size, huffman_codes[coefficient]))\n",
    "            run_length = 0\n",
    "\n",
    "    # Add end-of-block (EOB) symbol if needed\n",
    "    if run_length > 0:\n",
    "        encoded.append((0, 0, None))  # EOB marker\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entropy encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(image_path, qmat):\n",
    "\n",
    "    image = image_process(image_path)\n",
    "\n",
    "    dct = compute_DCT(image, qmat)\n",
    "\n",
    "    # calc diff\n",
    "    dct_diff = dct - np.roll(dct, 8, axis=1)\n",
    "    dct_diff[:,:8] = dct[:,:8]\n",
    "    \n",
    "    # get huffman for all blocks\n",
    "    print(type(dct[0,0]))\n",
    "    print(type(dct_diff[0,0]))\n",
    "    unique_values, counts = np.unique(dct_diff, return_counts=True)\n",
    "    freq_table = dict(zip(unique_values, counts))\n",
    "    freq_table.pop(0, None)\n",
    "    huffman_codes = generate_huffman_codes(freq_table)\n",
    "    encoded = []\n",
    "    # run length code\n",
    "    zigzag_ind = zigzag_order(8)\n",
    "    for i in range(dct_diff.shape[1]//8):\n",
    "        block = dct_diff[:, 8*i:8*i+8]\n",
    "        zigzag_block = [block[x, y] for x, y in zigzag_ind]\n",
    "        encoded_block = run_length_encode(zigzag_block, huffman_codes)\n",
    "        encoded += encoded_block\n",
    "    \n",
    "    return encoded, huffman_codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_compressed_file(filename, quant_matrix, huffman_table, encoded_data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.save(f, quant_matrix)\n",
    "        np.save(f, huffman_table)\n",
    "        np.save(f, encoded_data)\n",
    "        \n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f\"Size of the file '{filename}': {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128 128 128 ... 128 128 128]\n",
      " [128 128 128 ... 128 128 128]\n",
      " [128 128 128 ... 128 128 128]\n",
      " ...\n",
      " [128 128 128 ... 128 128 128]\n",
      " [128 128 128 ... 128 128 128]\n",
      " [128 128 128 ... 128 128 128]]\n",
      "122.0\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "23384\n",
      "Size of the file 'compressed_image.dat': 11844 bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from bitstring import BitArray\n",
    "def write_compressed_file(filename, quant_matrix, huffman_table, encoded_data, is_color=True):\n",
    "    with open(filename, 'wb') as f:\n",
    "        \n",
    "        file_size = 0  \n",
    "        f.write(struct.pack('I', file_size))\n",
    "        \n",
    "        \n",
    "        color_flag = 1 if is_color else 0\n",
    "        f.write(struct.pack('B', color_flag))\n",
    "        \n",
    "        huffman_list = list(huffman_table.items())\n",
    "        huff_bstream = BitArray()\n",
    "        f.write(struct.pack('I', len(huffman_list)))  # Write the number of entries\n",
    "        \n",
    "        for coeff, huff_code in huffman_list:\n",
    "            coeff_bit = BitArray(int=coeff, length=12)\n",
    "            huff_len_bit = BitArray(uint=len(huff_code), length=4)\n",
    "            huff_bit = BitArray(bin=huff_code)\n",
    "            huff_bstream += coeff_bit + huff_len_bit + huff_bit\n",
    "\n",
    "        huff_bstream.tofile(f)\n",
    "        \n",
    "        \n",
    "        # Write the quantization matrix (assuming it's a 2D NumPy array)\n",
    "        quant_matrix_size = quant_matrix.shape[0] * quant_matrix.shape[1]\n",
    "        f.write(struct.pack('I', quant_matrix_size))  # Total elements in the matrix\n",
    "        quant_matrix.tofile(f)  # Write the quantization matrix as raw binary data\n",
    "        \n",
    "        # Write the encoded data (bit stream)\n",
    "        f.write(struct.pack('I', len(encoded_data)))  # Length of the encoded stream\n",
    "        final_bitstream = BitArray()\n",
    "        bitstream_len = 0\n",
    "        for run_len, code_len, huff_code in encoded_data:\n",
    "            run_len_bit = BitArray(uint=run_len, length=4)\n",
    "            code_len_bit = BitArray(uint=code_len, length=4)\n",
    "            if huff_code == None:\n",
    "                bitstream_len += 8\n",
    "                continue\n",
    "            huff_code_bit = BitArray(bin=huff_code)\n",
    "            final_bitstream += run_len_bit + code_len_bit + huff_code_bit\n",
    "            bitstream_len += 8 + code_len\n",
    "        final_bitstream.tofile(f)\n",
    "        # Update the file size at the beginning\n",
    "        current_position = f.tell()  # Current position after writing\n",
    "        f.seek(0)  # Go back to the start of the file\n",
    "        f.write(struct.pack('I', current_position))  # Write the actual file size\n",
    "        f.seek(current_position)  # Return to the end of the file to continue writing\n",
    "\n",
    "# Example usage\n",
    "quant_matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61], \n",
    "                         [12, 12, 14, 19, 26, 58, 60, 55], \n",
    "                         [14, 13, 16, 24, 40, 57, 69, 56], \n",
    "                         [14, 17, 22, 29, 51, 87, 80, 62], \n",
    "                         [18, 22, 37, 56, 68, 109, 103, 77], \n",
    "                         [24, 35, 55, 64, 81, 104, 113, 92], \n",
    "                         [49, 64, 78, 87, 103, 121, 120, 101], \n",
    "                         [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "\n",
    "# Huffman table (example: DCT coefficient and Huffman code)\n",
    "# huffman_table = {\n",
    "#     0: \"0001\", 1: \"0010\", 2: \"0011\", 3: \"0100\", 4: \"0101\",\n",
    "#     5: \"0110\", 6: \"0111\", 7: \"1000\"\n",
    "# }\n",
    "\n",
    "# # Example encoded data (run-length, code-length, Huffman code)\n",
    "# encoded_data = [(1, 4, \"0001\"), (2, 3, \"001\"), (3, 5, \"01000\")]\n",
    "encoding, hufftable = encode(\"coil-20-unproc/obj1__0.png\", quant_matrix)\n",
    "print(os.path.getsize(\"coil-20-unproc/obj1__0.png\"))\n",
    "# Writing to a file\n",
    "write_compressed_file(\"compressed_image.dat\", quant_matrix, hufftable, encoding)\n",
    "filename = \"compressed_image.dat\"\n",
    "file_size = os.path.getsize(filename)\n",
    "print(f\"Size of the file '{filename}': {file_size} bytes\")\n",
    "\n",
    "# Open the file in binary read mode\n",
    "with open(filename, 'rb') as f:\n",
    "    # Read the entire file content as bytes\n",
    "    file_data = f.read()\n",
    "\n",
    "# Print each byte in the file\n",
    "# for byte in file_data:\n",
    "#     print(f\"{byte:08b}\")  # Print the byte in binary format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_compressed_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        quant_matrix = np.load(f)\n",
    "        huffman_table = np.load(f)\n",
    "        encoded_data = np.load(f)\n",
    "    return quant_matrix, huffman_table, encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decoding run length encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rle_data(encoded_bits, huffman_decoder):\n",
    "    \"\"\"\n",
    "    Decode RLE encoded data to reconstruct the original quantized 8x8 DCT block.\n",
    "\n",
    "    Parameters:\n",
    "    - encoded_bits (str): Binary string containing RLE encoded data.\n",
    "    - huffman_decoder (dict): Dictionary mapping Huffman codes to original coefficients.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Reconstructed 8x8 DCT block.\n",
    "    \"\"\"\n",
    "    decoded_coefficients = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(encoded_bits):\n",
    "        # Read 4 bits for run-length and 4 bits for size\n",
    "        run_length = int(encoded_bits[i:i+4], 2)\n",
    "        size = int(encoded_bits[i+4:i+8], 2)\n",
    "        i += 8\n",
    "\n",
    "        if size == 0:  # End-of-Block (EOB) marker\n",
    "            break\n",
    "\n",
    "        # Decode the Huffman code to get the coefficient\n",
    "        huffman_code = \"\"\n",
    "        while huffman_code not in huffman_decoder:\n",
    "            huffman_code += encoded_bits[i]\n",
    "            i += 1\n",
    "        coefficient = huffman_decoder[huffman_code]\n",
    "\n",
    "        # Add zeros for the run-length\n",
    "        decoded_coefficients.extend([0] * run_length)\n",
    "        decoded_coefficients.append(coefficient)\n",
    "\n",
    "    # Fill remaining zeros to complete the block (8x8 = 64 elements)\n",
    "    while len(decoded_coefficients) < 64:\n",
    "        decoded_coefficients.append(0)\n",
    "\n",
    "    # Reshape the list into an 8x8 block\n",
    "    return np.array(decoded_coefficients).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "encode() missing 1 required positional argument: 'qmat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m----> 3\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m write_compressed_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello.ourjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, image, b, a)\n\u001b[1;32m      5\u001b[0m qmat, hufftree, enc \u001b[38;5;241m=\u001b[39m read_compressed_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello.ourjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: encode() missing 1 required positional argument: 'qmat'"
     ]
    }
   ],
   "source": [
    "image = np.random.randint(0, 10, (8, 8), dtype=np.uint8)\n",
    "\n",
    "a, b = encode(image)\n",
    "write_compressed_file(\"hello.ourjpeg\", image, b, a)\n",
    "qmat, hufftree, enc = read_compressed_file(\"hello.ourjpeg\")\n",
    "\n",
    "print(qmat)\n",
    "print(hufftree)\n",
    "print(enc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
